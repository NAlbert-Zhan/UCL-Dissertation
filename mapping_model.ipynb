{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from model import RNN,LSTM,GRU\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.25, 0.25, 0.25, 0.25]], [[0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.25, 0.25, 0.25, 0.25], [0.25, 0.25, 0.25, 0.25], [0.25, 0.25, 0.25, 0.25], [0.25, 0.25, 0.25, 0.25]]]\n"
     ]
    }
   ],
   "source": [
    "# def pad_time_series(data, target_length=None, padding_value=0.0):\n",
    "#     # Determine the target length if not provided\n",
    "#     if target_length is None:\n",
    "#         target_length = max(len(sample) for sample in data)\n",
    "\n",
    "#     for sample in data:\n",
    "#         if len(sample) < target_length:\n",
    "#             for _ in range(target_length - len(sample)):\n",
    "#                 sample.append([padding_value for _ in range(4)])\n",
    "\n",
    "#     return data\n",
    "\n",
    "# # Example usage:\n",
    "# data = [\n",
    "#     [[0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5]],   #report1 representation\n",
    "#     [[0.1, 0.2, 0.3, 0.5], [0.1, 0.2, 0.3, 0.5]]                                                                     #report2 representation\n",
    "# ]\n",
    "\n",
    "# target_length = 6\n",
    "# padded_data = pad_time_series(data, target_length, padding_value=0.25)\n",
    "# print(padded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/lenovo/Desktop/UCL/Final dissertation/code/ESGOverallData.csv')\n",
    "ESG_data = data['ESGData'].apply(eval)\n",
    "length = ESG_data.apply(len)\n",
    "\n",
    "\n",
    "def pad_time_series(data, target_length=None, padding_value=0.25):\n",
    "    if target_length is None:\n",
    "        target_length = length.mean()\n",
    "    \n",
    "    padded_data = []\n",
    "    for sample, length in zip(data, length):\n",
    "        current_length = len(sample)\n",
    "        if current_length < target_length:\n",
    "            sample += [[padding_value for _ in range(4)] for _ in range(int(target_length - current_length))]\n",
    "        elif current_length > target_length:\n",
    "            sample = sample[:int(target_length)]\n",
    "        padded_data.append(sample)\n",
    "\n",
    "    return padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = pad_time_series(data, target_length, padding_value=0.25)\n",
    "print(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_time_series(data, target_length=None, padding_value=0.25):\n",
    "    # Determine the target length if not provided\n",
    "    if target_length is None:\n",
    "        target_length = max(len(sample) for sample in data)\n",
    "\n",
    "    for sample in data:\n",
    "        if len(sample) < target_length:\n",
    "            for _ in range(target_length - len(sample)):\n",
    "                sample.append([padding_value for _ in range(4)])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression dataset\n",
    "class MyDataset1(data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.samples = X\n",
    "        self.labels = Y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        label = [self.labels[index]]\n",
    "        #print(label)\n",
    "        sample=torch.Tensor(sample).float()\n",
    "        label= torch.Tensor(label).float()\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def loop(model,train_loader,test_loader,optimizer,criterion,device,E=20):\n",
    "    loss_all=[]\n",
    "    for epoch in range(E): \n",
    "        loss_epoch=[]\n",
    "        print(epoch)\n",
    "        for samples, labels in train_loader:\n",
    "            samples=samples.to(device)\n",
    "            labels=labels.to(device)\n",
    "            #print(samples.shape)\n",
    "            #print(labels.shape)\n",
    "        # Set the flag to training mode\n",
    "            model.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(samples)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch.append(float(loss.cpu()))\n",
    "            #print(outputs)\n",
    "        print(sum(loss_epoch)/len(loss_epoch))\n",
    "        loss_all.append(sum(loss_epoch)/len(loss_epoch))\n",
    "\n",
    "    model.eval()\n",
    "    result=[]\n",
    "    for samples, true in test_loader:\n",
    "        samples=samples.to(device)\n",
    "        outputs = model(samples)\n",
    "        result.append(float(outputs.cpu()))\n",
    "        \n",
    "    return result,loss_epoch,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]],\n",
    "    [[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2],[0.3,0.4,0.1,0.2]]]\n",
    "y=[1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size=4\n",
    "learning_rate=0.000001\n",
    "epoch=150\n",
    "hidden_num=50\n",
    "output_dim=1 #if None put ''\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset1(x,y)\n",
    "train_loader=data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader=data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "23.935096263885498\n",
      "1\n",
      "23.932191371917725\n",
      "2\n",
      "23.929420471191406\n",
      "3\n",
      "23.926559925079346\n",
      "4\n",
      "23.923686981201172\n",
      "5\n",
      "23.921006679534912\n",
      "6\n",
      "23.91792106628418\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.91513729095459\n",
      "8\n",
      "23.912482023239136\n",
      "9\n",
      "23.909560680389404\n",
      "10\n",
      "23.90682554244995\n",
      "11\n",
      "23.904036045074463\n",
      "12\n",
      "23.901008367538452\n",
      "13\n",
      "23.89863157272339\n",
      "14\n",
      "23.895607948303223\n",
      "15\n",
      "23.892842769622803\n",
      "16\n",
      "23.88995122909546\n",
      "17\n",
      "23.88701105117798\n",
      "18\n",
      "23.88428223133087\n",
      "19\n",
      "23.88149917125702\n",
      "20\n",
      "23.87871241569519\n",
      "21\n",
      "23.876052141189575\n",
      "22\n",
      "23.873072624206543\n",
      "23\n",
      "23.870450496673584\n",
      "24\n",
      "23.867482900619507\n",
      "25\n",
      "23.864731311798096\n",
      "26\n",
      "23.86180090904236\n",
      "27\n",
      "23.859086275100708\n",
      "28\n",
      "23.85630965232849\n",
      "29\n",
      "23.853467106819153\n",
      "30\n",
      "23.85075044631958\n",
      "31\n",
      "23.848214387893677\n",
      "32\n",
      "23.84511947631836\n",
      "33\n",
      "23.842270851135254\n",
      "34\n",
      "23.83950400352478\n",
      "35\n",
      "23.83678913116455\n",
      "36\n",
      "23.834123373031616\n",
      "37\n",
      "23.831236839294434\n",
      "38\n",
      "23.828282833099365\n",
      "39\n",
      "23.825486660003662\n",
      "40\n",
      "23.8226780295372\n",
      "41\n",
      "23.819843530654907\n",
      "42\n",
      "23.817372798919678\n",
      "43\n",
      "23.814438819885254\n",
      "44\n",
      "23.811674118041992\n",
      "45\n",
      "23.808974981307983\n",
      "46\n",
      "23.806119441986084\n",
      "47\n",
      "23.80320167541504\n",
      "48\n",
      "23.800493240356445\n",
      "49\n",
      "23.797857403755188\n",
      "50\n",
      "23.795089960098267\n",
      "51\n",
      "23.791996479034424\n",
      "52\n",
      "23.78947901725769\n",
      "53\n",
      "23.786654829978943\n",
      "54\n",
      "23.783898949623108\n",
      "55\n",
      "23.780956506729126\n",
      "56\n",
      "23.778329014778137\n",
      "57\n",
      "23.775543808937073\n",
      "58\n",
      "23.772652626037598\n",
      "59\n",
      "23.769850373268127\n",
      "60\n",
      "23.767088890075684\n",
      "61\n",
      "23.7643301486969\n",
      "62\n",
      "23.76184058189392\n",
      "63\n",
      "23.75872778892517\n",
      "64\n",
      "23.75619411468506\n",
      "65\n",
      "23.753292560577393\n",
      "66\n",
      "23.75057291984558\n",
      "67\n",
      "23.74765157699585\n",
      "68\n",
      "23.74501132965088\n",
      "69\n",
      "23.74212145805359\n",
      "70\n",
      "23.73957109451294\n",
      "71\n",
      "23.73650050163269\n",
      "72\n",
      "23.733928680419922\n",
      "73\n",
      "23.73124670982361\n",
      "74\n",
      "23.728413820266724\n",
      "75\n",
      "23.725308895111084\n",
      "76\n",
      "23.72287940979004\n",
      "77\n",
      "23.720030546188354\n",
      "78\n",
      "23.71712064743042\n",
      "79\n",
      "23.714506149291992\n",
      "80\n",
      "23.711796283721924\n",
      "81\n",
      "23.708900451660156\n",
      "82\n",
      "23.706148505210876\n",
      "83\n",
      "23.70347547531128\n",
      "84\n",
      "23.700730800628662\n",
      "85\n",
      "23.697907209396362\n",
      "86\n",
      "23.695146083831787\n",
      "87\n",
      "23.692378520965576\n",
      "88\n",
      "23.689589738845825\n",
      "89\n",
      "23.686739921569824\n",
      "90\n",
      "23.683830499649048\n",
      "91\n",
      "23.681169867515564\n",
      "92\n",
      "23.678340315818787\n",
      "93\n",
      "23.67601180076599\n",
      "94\n",
      "23.672908306121826\n",
      "95\n",
      "23.67015838623047\n",
      "96\n",
      "23.6675386428833\n",
      "97\n",
      "23.66441774368286\n",
      "98\n",
      "23.66190528869629\n",
      "99\n",
      "23.659165143966675\n",
      "100\n",
      "23.65631914138794\n",
      "101\n",
      "23.65345788002014\n",
      "102\n",
      "23.65078115463257\n",
      "103\n",
      "23.64806890487671\n",
      "104\n",
      "23.645082473754883\n",
      "105\n",
      "23.642481327056885\n",
      "106\n",
      "23.639631509780884\n",
      "107\n",
      "23.636915683746338\n",
      "108\n",
      "23.63425612449646\n",
      "109\n",
      "23.631267189979553\n",
      "110\n",
      "23.62872314453125\n",
      "111\n",
      "23.626188278198242\n",
      "112\n",
      "23.623035192489624\n",
      "113\n",
      "23.620450973510742\n",
      "114\n",
      "23.617504596710205\n",
      "115\n",
      "23.614990234375\n",
      "116\n",
      "23.61198115348816\n",
      "117\n",
      "23.60951805114746\n",
      "118\n",
      "23.60664701461792\n",
      "119\n",
      "23.604020833969116\n",
      "120\n",
      "23.600865364074707\n",
      "121\n",
      "23.59820318222046\n",
      "122\n",
      "23.595475435256958\n",
      "123\n",
      "23.592689514160156\n",
      "124\n",
      "23.590236961841583\n",
      "125\n",
      "23.587247848510742\n",
      "126\n",
      "23.584407806396484\n",
      "127\n",
      "23.581677675247192\n",
      "128\n",
      "23.57928991317749\n",
      "129\n",
      "23.57615637779236\n",
      "130\n",
      "23.573635935783386\n",
      "131\n",
      "23.570784091949463\n",
      "132\n",
      "23.567885398864746\n",
      "133\n",
      "23.56523370742798\n",
      "134\n",
      "23.562495708465576\n",
      "135\n",
      "23.559714317321777\n",
      "136\n",
      "23.556685268878937\n",
      "137\n",
      "23.554092407226562\n",
      "138\n",
      "23.551490783691406\n",
      "139\n",
      "23.548781394958496\n",
      "140\n",
      "23.545918941497803\n",
      "141\n",
      "23.543274402618408\n",
      "142\n",
      "23.540436267852783\n",
      "143\n",
      "23.537667989730835\n",
      "144\n",
      "23.534852266311646\n",
      "145\n",
      "23.531911969184875\n",
      "146\n",
      "23.529345512390137\n",
      "147\n",
      "23.526439666748047\n",
      "148\n",
      "23.52414870262146\n",
      "149\n",
      "23.521015644073486\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "features_dim=np.array(x).shape[2]\n",
    "modelRNN=RNN.RNN_Model(features_dim,hidden_num,output_dim).to(device)\n",
    "optimizerRNN= optim.Adam(modelRNN.parameters(), lr=learning_rate)\n",
    "resultRNN,lossRNN,modelRNN=loop(modelRNN,train_loader,test_loader,optimizerRNN,criterion,device,E=epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
